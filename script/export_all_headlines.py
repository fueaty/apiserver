#!/usr/bin/env python3
"""
å¯¼å‡ºå…¨é‡é‡‡é›†åº“æ•°æ®çš„è„šæœ¬
ç”¨äºåˆ†ææ™ºèƒ½é€‰æå¼•æ“éœ€æ±‚
"""

import sys
import os
import json
from typing import List, Dict, Any
from datetime import datetime, timedelta


# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
# sys.path.append(os.path.dirname(os.path.abspath(__file__)))
sys.path.append("..")

from app.services.feishu.feishu_service import FeishuService
from app.core.config import config_manager
import app.wework.file_push as file_push
import app.wework.notification_push as notification_push

today = datetime.now().strftime("%Y-%m-%d")

async def export_all_headlines_to_json(output_file: str = "all_headlines_data.json"):
    """å¯¼å‡ºé£ä¹¦å¤šç»´è¡¨æ ¼ä¸­çš„å…¨é‡é‡‡é›†æ•°æ®åˆ°JSONæ–‡ä»¶"""
    try:
        # åˆå§‹åŒ–é£ä¹¦æœåŠ¡
        feishu_service = FeishuService()
        
        # è·å–é…ç½®
        creds = config_manager.get_credentials()
        app_token = creds.get("feishu", {}).get("tables", {}).get("headlines", {}).get("app_token")
        table_id = creds.get("feishu", {}).get("tables", {}).get("headlines", {}).get("table_id")
        
        if not app_token or not table_id:
            print("âŒ é£ä¹¦é…ç½®ç¼ºå¤±ï¼Œè¯·æ£€æŸ¥ config/credentials.yaml æ–‡ä»¶")
            return False
        
        print(f"ğŸ“± æ­£åœ¨ä»é£ä¹¦å¤šç»´è¡¨æ ¼è·å–å…¨é‡æ•°æ®...")
        print(f"   App Token: {app_token}")
        print(f"   Table ID: {table_id}")
        
        # è·å–æ‰€æœ‰è®°å½•ï¼ˆä½¿ç”¨è¾ƒå¤§çš„page_sizeä»¥å‡å°‘è¯·æ±‚æ¬¡æ•°ï¼‰
        all_records = []
        page_size = 10000  # æ¯é¡µè·å–100æ¡è®°å½•
        
        # å…ˆè·å–ç¬¬ä¸€é¡µ
        records = await feishu_service.list_records(app_token, table_id, page_size=page_size)
        
        if not records:
            msg = "âŒ æœªè·å–åˆ°ä»»ä½•è®°å½•"
            notification_push.send_message(f"âŒ æœªè·å–åˆ°ä»»ä½•è®°å½•")
            print(msg)
            return False

        today_str = today + " 00:00:00"
        print(f"   ç­›é€‰ä»Šå¤©æ•°æ®ï¼ˆä»Šå¤©ä¸º {today_str}ï¼‰")
        # æå–è®°å½•æ•°æ®
        for record in records:
            if "fields" in record:
                time_info = record["fields"]["collected_at"]
                data = datetime.fromisoformat(time_info).time()
                if data >= datetime.strptime(today_str, "%Y-%m-%d %H:%M:%S").time():
                    all_records.append(record["fields"])
        
        print(f"   å·²è·å– {len(all_records)} æ¡è®°å½•")
        
        msg = f"âœ… å·²è·å– {len(all_records)} æ¡è®°å½•"
        print(msg)
        
        # ä¿å­˜åˆ°JSONæ–‡ä»¶
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(all_records, f, ensure_ascii=False, indent=2)
        
        msg = f"âœ… æ•°æ®å·²ä¿å­˜åˆ° {output_file}"
        notification_push.send_message(msg)
        print(msg)
        file_push.send_file_message(output_file)
        return True
        
    except Exception as e:
        msg = f"âŒ è·å–æ•°æ®è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}"
        notification_push.send_message(msg)
        print(msg)
        import traceback
        traceback.print_exc()
        return False


def analyze_data_for_selection_engine(json_file: str = "all_headlines_data.json"):
    """åˆ†ææ•°æ®ä»¥æ€»ç»“æ™ºèƒ½é€‰æå¼•æ“çš„æ ¸å¿ƒéœ€æ±‚"""
    try:
        with open(json_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        print(f"\nğŸ“Š æ™ºèƒ½é€‰æå¼•æ“éœ€æ±‚åˆ†ææŠ¥å‘Š:")
        print(f"   æ€»è®°å½•æ•°: {len(data)}")
        
        # ç»Ÿè®¡å„å­—æ®µå‡ºç°é¢‘ç‡
        field_stats = {}
        for record in data:
            for field in record.keys():
                field_stats[field] = field_stats.get(field, 0) + 1
        
        print(f"\n   å­—æ®µåˆ†å¸ƒ:")
        for field, count in sorted(field_stats.items(), key=lambda x: x[1], reverse=True):
            percentage = (count / len(data)) * 100
            print(f"   - {field}: {count} ({percentage:.1f}%)")
        
        # ç»Ÿè®¡å„ç«™ç‚¹æ•°æ®åˆ†å¸ƒ
        site_stats = {}
        for record in data:
            site = record.get("site_code", "unknown")
            site_stats[site] = site_stats.get(site, 0) + 1
            
        print(f"\n   ç«™ç‚¹åˆ†å¸ƒ:")
        for site, count in sorted(site_stats.items(), key=lambda x: x[1], reverse=True):
            percentage = (count / len(data)) * 100
            print(f"   - {site}: {count} ({percentage:.1f}%)")
        
        # çƒ­åº¦å€¼åˆ†æ
        hot_values = []
        for record in data:
            hot = record.get("hot")
            if hot is not None:
                try:
                    hot_values.append(int(hot))
                except (ValueError, TypeError):
                    pass
        
        if hot_values:
            avg_hot = sum(hot_values) / len(hot_values)
            max_hot = max(hot_values)
            min_hot = min(hot_values)
            print(f"\n   çƒ­åº¦å€¼åˆ†æ:")
            print(f"   - å¹³å‡çƒ­åº¦: {avg_hot:.0f}")
            print(f"   - æœ€é«˜çƒ­åº¦: {max_hot}")
            print(f"   - æœ€ä½çƒ­åº¦: {min_hot}")
        
        # æ’ååˆ†æ
        rank_values = []
        for record in data:
            rank = record.get("rank")
            if rank is not None:
                try:
                    rank_values.append(int(rank))
                except (ValueError, TypeError):
                    pass
        
        if rank_values:
            avg_rank = sum(rank_values) / len(rank_values)
            max_rank = max(rank_values)
            min_rank = min(rank_values)
            print(f"\n   æ’ååˆ†æ:")
            print(f"   - å¹³å‡æ’å: {avg_rank:.1f}")
            print(f"   - æœ€é«˜æ’å: {max_rank}")
            print(f"   - æœ€ä½æ’å: {min_rank}")
        
        # æ˜¾ç¤ºç¤ºä¾‹æ•°æ®
        print(f"\n   ç¤ºä¾‹æ•°æ® (å‰5æ¡):")
        for i, record in enumerate(data[:5]):
            print(f"   è®°å½• {i+1}:")
            for key, value in record.items():
                print(f"     {key}: {value}")
            print()
        
    except Exception as e:
        print(f"âŒ åˆ†æè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    import asyncio
    
    # å¯¼å‡ºæ•°æ®
    print("ğŸš€ å¼€å§‹å¯¼å‡ºé£ä¹¦å¤šç»´è¡¨æ ¼å…¨é‡æ•°æ®...")
    success = asyncio.run(export_all_headlines_to_json())
    
    if success:
        # åˆ†ææ•°æ®
        analyze_data_for_selection_engine()
        print("\nâœ… æ•°æ®å¯¼å‡ºå’Œåˆ†æå®Œæˆ")
    else:
        print("\nâŒ æ•°æ®å¯¼å‡ºå¤±è´¥")
        sys.exit(1)