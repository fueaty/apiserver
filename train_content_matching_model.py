#!/usr/bin/env python3
"""
å†…å®¹åŒ¹é…æ¨¡å‹è®­ç»ƒè„šæœ¬
æ­¤è„šæœ¬ç”¨äºåœ¨Windowsç¯å¢ƒä¸‹è®­ç»ƒå†…å®¹åŒ¹é…æ¨¡å‹ï¼Œç„¶åéƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒ
"""

import json
import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, accuracy_score
import joblib
import jieba
import re
from typing import List, Dict, Any

# æ¨¡æ‹Ÿå¹³å°åå¥½æ•°æ®ï¼ˆå®é™…åº”ç”¨ä¸­åº”ä»é…ç½®æ–‡ä»¶ä¸­è¯»å–ï¼‰
PLATFORM_PREFERENCES = {
    "weibo": ["ç¤¾ä¼šçƒ­ç‚¹", "å¨±ä¹èµ„è®¯", "ç”Ÿæ´»åˆ†äº«", "æ˜æ˜Ÿ", "å…«å¦", "çƒ­æœ"],
    "zhihu": ["ç§‘æŠ€ä¸“ä¸šåˆ†æ", "æŠ€æœ¯è®¨è®º", "å®ç”¨æŠ€å·§", "èµ„æºç›˜ç‚¹", "æ·±åº¦å¥½æ–‡"],
    "toutiao": ["å®æ—¶æ”¿ç­–å¿«è®¯", "ç¤¾ä¼šæ–°é—»æ‘˜è¦", "ç§‘æŠ€çƒ­ç‚¹çŸ­è®¯", "å¤§ä¼—åŒ–è¯é¢˜"],
    "xiaohongshu": ["è§†è§‰åŒ–å¹²è´§", "ç©¿æ­æ”»ç•¥", "å®¶å±…æ”¹é€ ", "è®¾è®¡åˆ†äº«", "ç”Ÿæ´»æ–¹å¼"]
}

def preprocess_text(text: str) -> str:
    """
    æ–‡æœ¬é¢„å¤„ç†å‡½æ•°
    """
    # å»é™¤ç‰¹æ®Šå­—ç¬¦å’Œæ•°å­—
    text = re.sub(r'[^\w\s]', '', text)
    text = re.sub(r'\d+', '', text)
    
    # ä¸­æ–‡åˆ†è¯
    words = jieba.cut(text)
    return ' '.join(words)

def generate_training_data(sample_size: int = 1000) -> pd.DataFrame:
    """
    ç”Ÿæˆæ¨¡æ‹Ÿè®­ç»ƒæ•°æ®
    å®é™…åº”ç”¨ä¸­åº”ä»çœŸå®æ•°æ®ä¸­æå–
    """
    # æ¨¡æ‹Ÿçƒ­ç‚¹æ ‡é¢˜æ•°æ®
    sample_titles = [
        "åˆä¸€å®¶ç”µå·¨å¤´å®˜å®£é€ è½¦",
        "å¤©æ°”ä¸‹é›¨æ—¶é¸Ÿéƒ½åœ¨å¹²å˜›ï¼Ÿ",
        "å°å‹åˆ›ä¸šæŒ‡å— #å¹²è´§",
        "æ±Ÿè‹çœå§”ä¹¦è®°ä¸ºæ³°å·é˜Ÿé¢å¥–",
        "è‹è¶…æ³°å·é˜Ÿå† å†›",
        "ä¸­å›½äººæœ‰7å¼ å¤ªç©ºå…¨å®¶ç¦äº†",
        "ä½ å¥½æ˜ŸæœŸå…­ä¸‹æœŸå¼ å‡Œèµ«",
        "æ³°å·é‡‘ç¿ç¿",
        "DRGæ—©ç‚¹ å›å®¶å§",
        "æ— é™æš–æš–",
        "å…¨å›½1%äººå£æŠ½æ ·è°ƒæŸ¥",
        "ä¹…é…·é‡‡è®¿",
        "æ³°å· ä¸€é»‘åˆ°åº•",
        "æœ€æ–°Pythonç¼–ç¨‹æŠ€å·§åˆ†äº«",
        "ä»Šæ—¥ç©¿æ­æŒ‡å—ï¼šç§‹å­£æ—¶å°šæ­é…",
        "ç§‘æŠ€è¡Œä¸šæœ€æ–°å‘å±•è¶‹åŠ¿åˆ†æ",
        "äººå·¥æ™ºèƒ½åœ¨åŒ»ç–—é¢†åŸŸçš„åº”ç”¨",
        "5GæŠ€æœ¯æ”¹å˜æœªæ¥ç”Ÿæ´»",
        "æ–°èƒ½æºæ±½è½¦å¸‚åœºå‰æ™¯å±•æœ›",
        "åŒºå—é“¾æŠ€æœ¯åŸç†è¯¦è§£"
    ]
    
    # æ‰©å±•æ•°æ®é›†
    titles = []
    platforms = []
    
    for _ in range(sample_size):
        title = np.random.choice(sample_titles)
        platform = np.random.choice(list(PLATFORM_PREFERENCES.keys()))
        
        titles.append(title)
        platforms.append(platform)
    
    return pd.DataFrame({
        'title': titles,
        'platform': platforms
    })

def extract_features(df: pd.DataFrame) -> pd.DataFrame:
    """
    ç‰¹å¾æå–
    """
    # æ–‡æœ¬é¢„å¤„ç†
    df['processed_title'] = df['title'].apply(preprocess_text)
    
    # è®¡ç®—ä¸å„å¹³å°åå¥½çš„åŒ¹é…åº¦
    for platform, preferences in PLATFORM_PREFERENCES.items():
        df[f'{platform}_match_score'] = df['title'].apply(
            lambda x: sum(1 for pref in preferences if pref in x) / len(preferences)
        )
    
    return df

def train_model():
    """
    è®­ç»ƒå†…å®¹åŒ¹é…æ¨¡å‹
    """
    print("ğŸš€ å¼€å§‹è®­ç»ƒå†…å®¹åŒ¹é…æ¨¡å‹...")
    
    # ç”Ÿæˆè®­ç»ƒæ•°æ®
    print("   ç”Ÿæˆè®­ç»ƒæ•°æ®...")
    df = generate_training_data(2000)
    
    # ç‰¹å¾æå–
    print("   æå–ç‰¹å¾...")
    df = extract_features(df)
    
    # å‡†å¤‡ç‰¹å¾å’Œæ ‡ç­¾
    feature_columns = [f'{p}_match_score' for p in PLATFORM_PREFERENCES.keys()]
    X = df[feature_columns]
    y = df['platform']
    
    # åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42
    )
    
    # è®­ç»ƒæ¨¡å‹
    print("   è®­ç»ƒæ¨¡å‹...")
    model = RandomForestClassifier(n_estimators=100, random_state=42)
    model.fit(X_train, y_train)
    
    # è¯„ä¼°æ¨¡å‹
    y_pred = model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    print(f"   æ¨¡å‹å‡†ç¡®ç‡: {accuracy:.4f}")
    
    # ä¿å­˜æ¨¡å‹å’Œå‘é‡åŒ–å™¨
    print("   ä¿å­˜æ¨¡å‹...")
    joblib.dump(model, 'content_matching_model.pkl')
    joblib.dump(PLATFORM_PREFERENCES, 'platform_preferences.pkl')
    
    print("âœ… æ¨¡å‹è®­ç»ƒå®Œæˆ!")
    print(f"   æ¨¡å‹æ–‡ä»¶: content_matching_model.pkl")
    print(f"   å¹³å°åå¥½æ–‡ä»¶: platform_preferences.pkl")
    
    return model

def test_model():
    """
    æµ‹è¯•æ¨¡å‹
    """
    print("\nğŸ” æµ‹è¯•æ¨¡å‹...")
    
    # åŠ è½½æ¨¡å‹
    model = joblib.load('content_matching_model.pkl')
    
    # æµ‹è¯•æ ·ä¾‹
    test_titles = [
        "æ±Ÿè‹çœå§”ä¹¦è®°ä¸ºæ³°å·é˜Ÿé¢å¥–",
        "æœ€æ–°Pythonç¼–ç¨‹æŠ€å·§åˆ†äº«",
        "ä»Šæ—¥ç©¿æ­æŒ‡å—ï¼šç§‹å­£æ—¶å°šæ­é…",
        "äººå·¥æ™ºèƒ½åœ¨åŒ»ç–—é¢†åŸŸçš„åº”ç”¨"
    ]
    
    # æå–ç‰¹å¾
    test_data = pd.DataFrame({'title': test_titles})
    test_data = extract_features(test_data)
    
    feature_columns = [f'{p}_match_score' for p in PLATFORM_PREFERENCES.keys()]
    X_test = test_data[feature_columns]
    
    # é¢„æµ‹
    predictions = model.predict(X_test)
    probabilities = model.predict_proba(X_test)
    
    print("   æµ‹è¯•ç»“æœ:")
    for i, title in enumerate(test_titles):
        print(f"     æ ‡é¢˜: {title}")
        print(f"     é¢„æµ‹å¹³å°: {predictions[i]}")
        print(f"     ç½®ä¿¡åº¦: {max(probabilities[i]):.4f}")
        print()

if __name__ == "__main__":
    # è®­ç»ƒæ¨¡å‹
    model = train_model()
    
    # æµ‹è¯•æ¨¡å‹
    test_model()
    
    print("\nğŸ‰ æ¨¡å‹è®­ç»ƒå’Œæµ‹è¯•å®Œæˆ!")
    print("   æ‚¨å¯ä»¥å°†ç”Ÿæˆçš„æ¨¡å‹æ–‡ä»¶éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒä½¿ç”¨")